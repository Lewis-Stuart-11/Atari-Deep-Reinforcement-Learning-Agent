{
  "PongDeterministic-v4":
      {
        "0": {
              "learning_technique": "DQL",
              "learning_rate": 5e-05,
              "epsilon_strategy": "Epsilon Greedy Linear Advanced",
              "epsilon_values": [1, 0.1, 0.01, 0.0008, 1e-05],
              "discount": 0.99,
              "resize": [80, 60],
              "resize_interpolation_mode": "BILINEAR",
              "crop_values": {"percentage_crop_width": [0.06, 0.94], "percentage_crop_height": [0.17, 0.92]},
              "screen_process_type": "append",
              "colour_type": "gray",
              "prev_states_queue_size": 4,
              "policy": "DQN_CNN_Advanced",
              "policy_parameters": {"kernel_sizes": [8, 4, 3], "strides": [4, 2, 1], "neurons_per_layer": [32, 64, 64, 620]},
              "batch_size": 60,
              "memory_size": 25000,
              "memory_size_start": 10000,
              "target_update": 6,
              "update_factor": 4,
              "reward_scheme": {"use_given_reward": true, "lives_change_reward": 0, "one_life_game": false,
                                "normalise_rewards": false, "end_on_negative": false}
            }
      },

  "BreakoutDeterministic-v4":
      {
        "0": {
              "learning_technique": "DQL",
              "learning_rate": 2e-05,
              "epsilon_strategy": "Epsilon Greedy Linear Advanced",
              "epsilon_values": {"start": 1, "middle": 0.1, "end": 0.01, "decay_linear": 0.0001, "end_decay_linear": 1e-05},
              "discount": 0.99,
              "resize": [84, 84],
              "resize_interpolation_mode": "BILINEAR",
              "crop_values": {"percentage_crop_width": [0.05, 0.95], "percentage_crop_height":  [0.45, 0.95]},
              "screen_process_type": "morph",
              "colour_type": "gray",
              "prev_states_queue_size": 4,
              "policy": "DQN_CNN_Advanced",
              "policy_parameters": {"kernel_sizes": [8, 4, 3], "strides": [4, 2, 1], "neurons_per_layer": [32, 64, 64, 620]},
              "batch_size": 20,
              "memory_size": 25000,
              "memory_size_start": 10000,
              "target_update": 6,
              "update_factor": 4,
              "reward_scheme": {"use_given_reward": false, "lives_change_reward": -10, "one_life_game": false,
                                "normalise_rewards": false, "end_on_negative": false}
          },
        "1": {
              "learning_technique": "DQL",
              "learning_rate": 2e-05,
              "epsilon_strategy": "Epsilon Greedy Reward",
              "epsilon_values": {"start": 1, "end": 0.2, "decay_linear": 0.0001, "reward_incrementation": 3,
                                 "reward_target": 100, "reward_decay":  0.01},
              "discount": 0.99,
              "resize": [84, 84],
              "resize_interpolation_mode": "BILINEAR",
              "crop_values": {"percentage_crop_width": [0.05, 0.95], "percentage_crop_height":  [0.45, 0.95]},
              "screen_process_type": "append",
              "colour_type": "gray",
              "prev_states_queue_size": 4,
              "policy": "DQN_CNN_Advanced",
              "policy_parameters": {"kernel_sizes": [8, 4, 3], "strides": [4, 2, 1], "neurons_per_layer": [32, 64, 64, 500]},
              "batch_size": 20,
              "memory_size": 25000,
              "memory_size_start": 10000,
              "target_update": 6,
              "update_factor": 4,
              "reward_scheme": {"use_given_reward": true, "lives_change_reward": -10, "one_life_game": false,
                                "normalise_rewards": false, "end_on_negative": false}
          },
        "2": {
              "learning_technique": "reinforce",
              "learning_rate": 5e-05,
              "epsilon_strategy": "Epsilon Greedy Linear Advanced",
              "epsilon_values": {"start": 1, "middle": 0.1, "end": 0.01, "decay_linear": 0.0001, "end_decay_linear": 1e-05},
              "discount": 0.998,
              "resize": [84, 84],
              "resize_interpolation_mode": "BILINEAR",
              "crop_values": {"percentage_crop_width": [0.05, 0.95], "percentage_crop_height":  [0.25, 0.95]},
              "screen_process_type": "append",
              "colour_type": "gray",
              "prev_states_queue_size": 4,
              "policy": "DQN_CNN_Advanced",
              "policy_parameters": {"kernel_sizes": [8, 4, 3], "strides": [4, 2, 1], "neurons_per_layer": [32, 64, 64, 620]},
              "improve_episode_factor": 1,
              "reward_scheme": {"use_given_reward": true, "lives_change_reward": -10, "one_life_game": false,
                                "normalise_rewards": false, "end_on_negative": false}
          }
      },

  "MsPacmanDeterministic-v0":
      {
        "0": {
              "learning_technique": "DQL",
              "learning_rate": 5e-05,
              "epsilon_strategy": "Epsilon Greedy Linear Advanced",
              "epsilon_values": {"start": 1, "middle": 0.1, "end": 0.01, "decay_linear": 0.0004, "end_decay_linear": 1e-05},
              "discount": 0.995,
              "resize": [100, 90],
              "resize_interpolation_mode": "NEAREST",
              "crop_values": {"percentage_crop_width": [0, 1], "percentage_crop_height":  [0.01, 0.81]},
              "screen_process_type": "standard",
              "colour_type": "rgb",
              "prev_states_queue_size": 1,
              "policy": "DQN_CNN_Advanced",
              "policy_parameters": {"kernel_sizes": [8, 4, 3], "strides": [4, 2, 1], "neurons_per_layer": [32, 64, 64, 512]},
              "batch_size": 40,
              "memory_size": 25000,
              "memory_size_start": 5000,
              "target_update": 4,
              "update_factor": 6,
              "reward_scheme": {"use_given_reward": true, "lives_change_reward": -100, "one_life_game": false,
                                "normalise_rewards": false, "end_on_negative": false}
        },
         "1": {
              "learning_technique": "DQL",
              "learning_rate": 5e-05,
              "epsilon_strategy": "Epsilon Greedy Linear Advanced",
              "epsilon_values": {"start": 1, "middle": 0.1, "end": 0.01, "decay_linear": 0.0001, "end_decay_linear": 1e-05},
              "discount": 0.999,
              "resize": [100, 90],
              "resize_interpolation_mode": "NEAREST",
              "crop_values": {"percentage_crop_width": [0, 1], "percentage_crop_height":  [0.01, 0.81]},
              "screen_process_type": "standard",
              "colour_type": "rgb",
              "prev_states_queue_size": 1,
              "policy": "DQN_CNN_Advanced",
              "policy_parameters": {"kernel_sizes": [8, 4, 3], "strides": [4, 2, 1], "neurons_per_layer": [32, 64, 64, 512]},
              "batch_size": 60,
              "memory_size": 25000,
              "memory_size_start": 5000,
              "target_update": 2,
              "update_factor": 10,
              "reward_scheme": {"use_given_reward": false, "lives_change_reward": 0, "one_life_game": true,
                                "normalise_rewards": false, "end_on_negative": false, "use_custom_env_rewards": true}
        }
      },

  "EnduroDeterministic-v0":
      {
        "0": {
              "learning_technique": "DQL",
              "learning_rate": 5e-05,
              "epsilon_strategy": "Epsilon Greedy Linear Advanced",
              "epsilon_values": {"start": 1, "middle": 0.1, "end": 0.01, "decay_linear": 0.002, "end_decay_linear": 0.0001},
              "discount": 0.995,
              "resize": [100, 90],
              "resize_interpolation_mode": "BILINEAR",
              "crop_values": {"percentage_crop_width": [0.05, 1], "percentage_crop_height":  [0.25, 0.73]},
              "screen_process_type": "standard",
              "colour_type": "rgb",
              "prev_states_queue_size": 1,
              "policy": "DQN_CNN_Advanced",
              "policy_parameters": {"kernel_sizes": [8, 4, 3], "strides": [4, 2, 1], "neurons_per_layer": [32, 64, 64, 512]},
              "batch_size": 40,
              "memory_size": 30000,
              "memory_size_start": 2000,
              "target_update": 4,
              "update_factor": 6,
              "reward_scheme": {"use_given_reward": true, "lives_change_reward": 0, "one_life_game": false,
                                "normalise_rewards": false, "end_on_negative": false}
        }
      },

  "CartPole-v0":
      {
        "0": {
              "learning_technique": "reinforce",
              "learning_rate": 0.001,
              "epsilon_strategy": "Epsilon Greedy Linear",
              "epsilon_values": {"start": 1, "end": 0.1, "decay_linear": 0.01},
              "discount": 0.99,
              "resize": [40, 90],
              "resize_interpolation_mode": "BILINEAR",
              "crop_values": {"percentage_crop_width": [0, 1], "percentage_crop_height":  [0.4, 0.8]},
              "screen_process_type": "difference",
              "colour_type": "rgb",
              "prev_states_queue_size": 2,
              "policy": "DQN",
              "policy_parameters": {"neurons_per_layer": [24, 32, 48]},
              "improve_episode_factor": 1,
              "reward_scheme": {"use_given_reward": true, "lives_change_reward": 0, "one_life_game": false,
                                "normalise_rewards": false, "end_on_negative": false}
          }
      }
}